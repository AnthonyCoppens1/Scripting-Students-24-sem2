{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webscraping - class of week 7\n",
    "- recap API's\n",
    "- making requests\n",
    "- work with the beautifulsoup\n",
    "- combining scraping and api's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap of API's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "\n",
    "sentence = input()\n",
    "url = f\"https://pirate.monkeyness.com/api/translate?english={sentence}\"\n",
    "\n",
    "response = requests.get(url)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dear Love Calculator user\n",
      "\n",
      "Test results for Brad Pitt who might be in love with Angelina Jolie\n",
      "Their love percentage is: 62.33%\n",
      "\n",
      "Message from our platform: Why aren't we dating yet???\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://the-love-calculator.p.rapidapi.com/love-calculator\"\n",
    "\n",
    "name1 = input()\n",
    "name2 = input()\n",
    "querystring = {\"fname\":name1,\"sname\":name2}\n",
    "\n",
    "headers = {\n",
    "\t\"x-rapidapi-key\": \"fd6f435c07msh3de62319fcfa275p143e5cjsn4293d86a9f09\",\n",
    "\t\"x-rapidapi-host\": \"the-love-calculator.p.rapidapi.com\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers, params=querystring)\n",
    "data = response.json()\n",
    "\n",
    "s = f\"\"\"\n",
    "Dear Love Calculator user\n",
    "\n",
    "Test results for {name1} who might be in love with {name2}\n",
    "Their love percentage is: {round(data[\"percentage match: \"],2)}%\n",
    "\n",
    "Message from our platform: {data[\"result: \"]}\n",
    "\"\"\"\n",
    "\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baloo appears in the following videogames:\n",
      "\n",
      "TaleSpin (NES video game)\n",
      "TaleSpin (Sega Genesis Video Game)\n",
      "The Jungle Book (video game)\n",
      "The Jungle Book Groove Party\n",
      "Disney Universe\n",
      "Kinect Disneyland Adventures\n",
      "Disney Infinity (series)\n",
      "Disney Crossy Road\n",
      "Disney Emoji Blitz\n",
      "Disney Magic Kingdoms\n",
      "Kingdom Hearts Union χ\n",
      "Disney Heroes: Battle Mode\n",
      "Disney Sorcerer's Arena\n",
      "Just Dance: Disney Party\n"
     ]
    }
   ],
   "source": [
    "# another api exercise on disney\n",
    "import json, requests\n",
    "url = \"https://api.disneyapi.dev/character\"\n",
    "\n",
    "response = requests.get(url)\n",
    "text = response.text\n",
    "data = json.loads(text)\n",
    "\n",
    "for character in data[\"data\"]:\n",
    "    if character[\"name\"] == \"Baloo\":\n",
    "        list = character[\"videoGames\"]\n",
    "\n",
    "print(\"Baloo appears in the following videogames:\\n\")\n",
    "for element in list:\n",
    "    print(element)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Webscraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1378\n"
     ]
    }
   ],
   "source": [
    "import requests, re\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/Elephant\"\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    html = response.text\n",
    "    #print(html)\n",
    "\n",
    "    regex = \"elephant|Elephant\"\n",
    "    matches = re.findall(regex, html)\n",
    "    print(len(matches))\n",
    "else:\n",
    "    print(\"try again\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with beautifulsoup\n",
    "install --> beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\python312\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\python312\\lib\\site-packages (from beautifulsoup4) (2.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>Elephant - Wikipedia</title>\n",
      "Elephant - Wikipedia\n",
      "['Elephant', '-', 'Wikipedia', 'Jump', 'to', 'content', 'Main', 'menu', 'Main', 'menu', 'move', 'to', 'sidebar', 'hide', 'Navigation', 'Main', 'pageContentsCurrent', 'eventsRandom', 'articleAbout', 'WikipediaContact', 'us', 'Contribute', 'HelpLearn', 'to', 'editCommunity', 'portalRecent', 'changesUpload', 'fileSpecial', 'pages', 'Search', 'Search', 'Appearance', 'Donate', 'Create', 'account', 'Log', 'in', 'Personal', 'tools', 'Donate', 'Create', 'account', 'Log', 'in']\n",
      "181\n",
      "343\n",
      "<h3 id=\"Evolution\">Evolution</h3>\n",
      "[<h3 id=\"Evolution\">Evolution</h3>, <h3 id=\"Living_species\">Living species</h3>, <h3 id=\"Ears_and_eyes\">Ears and eyes</h3>, <h3 id=\"Trunk\">Trunk</h3>, <h3 id=\"Teeth\">Teeth</h3>, <h3 id=\"Skin\">Skin</h3>, <h3 id=\"Legs,_locomotion,_and_posture\"><span id=\"Legs.2C_locomotion.2C_and_posture\"></span>Legs, locomotion, and posture</h3>, <h3 id=\"Internal_systems\">Internal systems</h3>, <h3 id=\"Sex_characteristics\">Sex characteristics</h3>, <h3 id=\"Social_organisation\">Social organisation</h3>, <h3 id=\"Sexual_behaviour\">Sexual behaviour</h3>, <h3 id=\"Birth_and_development\">Birth and development</h3>, <h3 id=\"Communication\">Communication</h3>, <h3 id=\"Intelligence_and_cognition\">Intelligence and cognition</h3>, <h3 id=\"Status\">Status</h3>, <h3 id=\"Threats\">Threats</h3>, <h3 id=\"Working_animal\">Working animal</h3>, <h3 id=\"Warfare\">Warfare</h3>, <h3 id=\"Zoos_and_circuses\">Zoos and circuses</h3>, <h3 id=\"Attacks\">Attacks</h3>, <h3 id=\"Cultural_significance\">Cultural significance</h3>]\n",
      "Evolution\n",
      "Living species\n",
      "Ears and eyes\n",
      "Trunk\n",
      "Teeth\n",
      "Skin\n",
      "Legs, locomotion, and posture\n",
      "Internal systems\n",
      "Sex characteristics\n",
      "Social organisation\n",
      "Sexual behaviour\n",
      "Birth and development\n",
      "Communication\n",
      "Intelligence and cognition\n",
      "Status\n",
      "Threats\n",
      "Working animal\n",
      "Warfare\n",
      "Zoos and circuses\n",
      "Attacks\n",
      "Cultural significance\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/Elephant\"\n",
    "response = requests.get(url)\n",
    "html = response.text\n",
    "\n",
    "soup = BeautifulSoup(html)\n",
    "#print(soup)\n",
    "#print(soup.prettify())\n",
    "print(soup.title)\n",
    "print(soup.title.get_text())\n",
    "\n",
    "print(soup.get_text()[0:500].split())\n",
    "print(soup.get_text().count(\"Elephant\"))\n",
    "print(soup.get_text().count(\"elephant\"))\n",
    "\n",
    "h3tags = soup.find(\"h3\")\n",
    "print(h3tags)\n",
    "\n",
    "h3tags = soup.find_all(\"h3\")\n",
    "print(h3tags)\n",
    "\n",
    "for element in h3tags:\n",
    "    print(element.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gajah – Acehnese\n",
      "Olifant – Afrikaans\n",
      "Elefant – Alemannic\n",
      "ዝሆን – Amharic\n",
      "हाथी – Angika\n",
      "Elpend – Old English\n",
      "فيل – Arabic\n",
      "Elefant – Aragonese\n",
      "Elefandu – Aromanian\n",
      "Elephantidae – Asturian\n",
      "हाथी – Awadhi\n",
      "Tapi'itĩmbuku – Guarani\n",
      "Fil – Azerbaijani\n",
      "فیل – South Azerbaijani\n",
      "Kunjara – Balinese\n",
      "Sama – Bambara\n",
      "হাতি – Bangla\n",
      "Gajah – Banjar\n",
      "Chhiūⁿ – Minnan\n",
      "Фил – Bashkir\n",
      "Слон – Belarusian\n",
      "Слон – Belarusian (Taraškievica orthography)\n",
      "Elepante – Central Bikol\n",
      "Слон – Bulgarian\n",
      "གླང་ཆེན། – Tibetan\n",
      "Slon – Bosnian\n",
      "Olifant – Breton\n",
      "Заан – Russia Buriat\n",
      "Elefants – Catalan\n",
      "Slon – Czech\n",
      "Nzou – Shona\n",
      "Elefante – Corsican\n",
      "Eliffant – Welsh\n",
      "Wɔbigu – Dagbani\n",
      "Elefanter – Danish\n",
      "Elefant – German\n",
      "Chį́į́h yee adilohii – Navajo\n",
      "Elevant – Estonian\n",
      "Ελέφαντας – Greek\n",
      "Пил – Erzya\n",
      "Elefante – Spanish\n",
      "Elefanto – Esperanto\n",
      "Elefante – Basque\n",
      "Atiglinyi – Ewe\n",
      "فیل – Persian\n",
      "Haanthi – Fiji Hindi\n",
      "Fílur – Faroese\n",
      "Éléphant – French\n",
      "Eilifint – Irish\n",
      "Elefant – Manx\n",
      "Fillär – Gagauz\n",
      "Ailbhean – Scottish Gaelic\n",
      "Elefante – Galician\n",
      "Пил – Ingush\n",
      "象 – Gan\n",
      "Njogu – Kikuyu\n",
      "હાથી – Gujarati\n",
      "𐌹𐌻𐍀𐌰𐌽𐌳𐌿𐍃 – Gothic\n",
      "Siong – Hakka Chinese\n",
      "Зан – Kalmyk\n",
      "코끼리 – Korean\n",
      "Giwa – Hausa\n",
      "Փղեր – Armenian\n",
      "हाथी – Hindi\n",
      "Slon – Croatian\n",
      "Elefanto – Ido\n",
      "Elepante – Iloko\n",
      "Gajah – Indonesian\n",
      "Indlovu – Zulu\n",
      "Fíll – Icelandic\n",
      "Elefante – Italian\n",
      "פיל – Hebrew\n",
      "Gajah – Javanese\n",
      "Nagguaatsoq – Kalaallisut\n",
      "ಆನೆ – Kannada\n",
      "ہۆس – Kashmiri\n",
      "Пілдер – Kazakh\n",
      "Olifans – Cornish\n",
      "Inzovu – Kinyarwanda\n",
      "Ndovu – Swahili\n",
      "Nzau – Kongo\n",
      "Elefan – Haitian Creole\n",
      "Fîl – Kurdish\n",
      "Пил – Kyrgyz\n",
      "Elefanc – Ladin\n",
      "Пил – Lak\n",
      "ຊ້າງ – Lao\n",
      "Elephantus – Latin\n",
      "Ziloņi – Latvian\n",
      "Фил – Lezghian\n",
      "Drambliai – Lithuanian\n",
      "Gaza – Nias\n",
      "Elefante – Ligurian\n",
      "Olifante – Limburgish\n",
      "Nzɔku – Lingala\n",
      "xanto – Lojban\n",
      "Liofant – Lombard\n",
      "Слон – Macedonian\n",
      "Elefanta – Malagasy\n",
      "ആന – Malayalam\n",
      "Iljunfant – Maltese\n",
      "Arewhana – Māori\n",
      "हत्ती – Marathi\n",
      "فيل – Egyptian Arabic\n",
      "فیل – Mazanderani\n",
      "Gajah – Malay\n",
      "ꯁꯥꯃꯨ – Manipuri\n",
      "Ɔson – Fanti\n",
      "Gajah – Minangkabau\n",
      "Chiông – Mindong\n",
      "Заан – Mongolian\n",
      "ဆင် – Burmese\n",
      "Olifanten – Dutch\n",
      "हात्ती – Nepali\n",
      "किसि – Newari\n",
      "ゾウ – Japanese\n",
      "Elefant – Norwegian Nynorsk\n",
      "Êléphant – Norman\n",
      "Elefant – Occitan\n",
      "ହାତୀ – Odia\n",
      "Fil – Uzbek\n",
      "ਹਾਥੀ – Punjabi\n",
      "ہاتھی – Western Punjabi\n",
      "Olifanti – Papiamento\n",
      "پیل – Pashto\n",
      "គជសារ – Khmer\n",
      "Elefant – Low German\n",
      "Słonie – Polish\n",
      "Elefante – Portuguese\n",
      "Fil – Crimean Tatar\n",
      "Elefant – Romanian\n",
      "Слон – Rusyn\n",
      "Слон – Russian\n",
      "Сэлиилэр – Yakut\n",
      "zu – Sakizaya\n",
      "Elefane – Samoan\n",
      "गजः – Sanskrit\n",
      "ᱦᱟᱹᱛᱤ – Santali\n",
      "ہاتھی – Saraiki\n",
      "Elephant – Scots\n",
      "Tlou – Southern Sotho\n",
      "Tlou – Northern Sotho\n",
      "Elefanti – Albanian\n",
      "අලි – Sinhala\n",
      "Elephant – Simple English\n",
      "هاٿي – Sindhi\n",
      "Slon – Slovenian\n",
      "Maroodi – Somali\n",
      "فیل – Central Kurdish\n",
      "Slon – Serbian\n",
      "Gajah – Sundanese\n",
      "Norsu – Finnish\n",
      "Elefant – Swedish\n",
      "Gadya – Tagalog\n",
      "யானை – Tamil\n",
      "Ilu – Kabyle\n",
      "Фил – Tatar\n",
      "ၸၢင်ႉ – Shan\n",
      "zo – Atayal\n",
      "ఏనుగు – Telugu\n",
      "ช้าง – Thai\n",
      "Akɔ̈ɔ̈n – Dinka\n",
      "Фил – Tajik\n",
      "ᎧᎹᎹ – Cherokee\n",
      "Tsêhe'êseeséhe – Cheyenne\n",
      "Nḓou – Venda\n",
      "ಆನೆ – Tulu\n",
      "Fil – Turkish\n",
      "Pil – Turkmen\n",
      "Zwuom – Tyap\n",
      "Слон – Udmurt\n",
      "Слон – Ukrainian\n",
      "ہاتھی – Urdu\n",
      "پىل – Uyghur\n",
      "Duzciengh – Zhuang\n",
      "Elefant – Veps\n",
      "Voi – Vietnamese\n",
      "Leefad – Volapük\n",
      "Elevant – Võro\n",
      "象 – Literary Chinese\n",
      "Olifantn – West Flemish\n",
      "Elepante – Waray\n",
      "Ñay – Wolof\n",
      "象 – Wu\n",
      "העלפאנד – Yiddish\n",
      "Erin – Yoruba\n",
      "象 – Cantonese\n",
      "Fil – Dimli\n",
      "Dromblīs – Samogitian\n",
      "象 – Chinese\n",
      "Eniin̄ – Obolo\n",
      "Gaja – Batak Mandailing\n",
      "Ajinakú geli – Fon\n",
      "Gajah – Iban\n",
      "Kǝmowon – Central Kanuri\n",
      "ᥓᥣᥒᥳ – Tai Nuea\n"
     ]
    }
   ],
   "source": [
    "# getting all of the languages and elephants in those languages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/Elephant\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text)\n",
    "\n",
    "listTags = soup.find_all(\"li\", {'class':\"interlanguage-link\"})\n",
    "for tag in listTags:\n",
    "    print(tag.a[\"title\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More images and regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/wikipedia.png\n",
      "/Soup_powder.jpg\n",
      "/Soup_Course_New.jpg\n",
      "/Seafood_chowder.jpg\n",
      "/Borscht_with_bread.jpg\n",
      "/Vegetable_beef_barley_soup.jpg\n",
      "/Chicken_Noodle_Soup.jpg\n",
      "/Reindeer_cheese_soup.jpg\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests, re\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/Soup\"\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(r.text)\n",
    "\n",
    "imgTags = soup.find_all('img')\n",
    "sources = [img['src'] for img in imgTags]\n",
    "\n",
    "results = re.findall(r'(/\\w+[.](jpg|png|gif))',str(sources))\n",
    "for url in results:\n",
    "    print(url[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#downloading images and storing them somewhere --> from weather website\n",
    "#https://www.meteoblue.com/nl/weer/webcams/kopenhagen_denemarken_2618425\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "url = \"https://www.meteoblue.com/nl/weer/webcams/kopenhagen_denemarken_2618425\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content,\"html.parser\")\n",
    "\n",
    "images = soup.find_all('img')\n",
    "\n",
    "#os.mkdir(f\"{os.getcwd()}/Images\") --> add this only 1 time to immediately create a folder and add all files/images there\n",
    "\n",
    "count = 0\n",
    "for img in images:\n",
    "    url = img[\"src\"]\n",
    "    filename = f\"Images/meteoblue_{str(count)}.jpg\"\n",
    "    r = requests.get(url, allow_redirects=True)\n",
    "    with open(filename, 'wb') as file:\n",
    "        file.write(r.content)\n",
    "    count += 1 \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
