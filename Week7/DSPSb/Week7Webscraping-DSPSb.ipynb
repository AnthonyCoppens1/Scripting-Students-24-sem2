{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webscraping - class of week 7\n",
    "- recap API's\n",
    "- making requests\n",
    "- work with the beautifulsoup\n",
    "- combining scraping and api's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap of API's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "\n",
    "sentence = input()\n",
    "url = f\"https://pirate.monkeyness.com/api/translate?english={sentence}\"\n",
    "\n",
    "response = requests.get(url)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dear Love Calculator user\n",
      "\n",
      "Test results for Brad Pitt who might be in love with Angelina Jolie\n",
      "Their love percentage is: 62.33%\n",
      "\n",
      "Message from our platform: Why aren't we dating yet???\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://the-love-calculator.p.rapidapi.com/love-calculator\"\n",
    "\n",
    "name1 = input()\n",
    "name2 = input()\n",
    "querystring = {\"fname\":name1,\"sname\":name2}\n",
    "\n",
    "headers = {\n",
    "\t\"x-rapidapi-key\": \"fd6f435c07msh3de62319fcfa275p143e5cjsn4293d86a9f09\",\n",
    "\t\"x-rapidapi-host\": \"the-love-calculator.p.rapidapi.com\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers, params=querystring)\n",
    "data = response.json()\n",
    "\n",
    "s = f\"\"\"\n",
    "Dear Love Calculator user\n",
    "\n",
    "Test results for {name1} who might be in love with {name2}\n",
    "Their love percentage is: {round(data[\"percentage match: \"],2)}%\n",
    "\n",
    "Message from our platform: {data[\"result: \"]}\n",
    "\"\"\"\n",
    "\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baloo appears in the following videogames:\n",
      "\n",
      "TaleSpin (NES video game)\n",
      "TaleSpin (Sega Genesis Video Game)\n",
      "The Jungle Book (video game)\n",
      "The Jungle Book Groove Party\n",
      "Disney Universe\n",
      "Kinect Disneyland Adventures\n",
      "Disney Infinity (series)\n",
      "Disney Crossy Road\n",
      "Disney Emoji Blitz\n",
      "Disney Magic Kingdoms\n",
      "Kingdom Hearts Union Ï‡\n",
      "Disney Heroes: Battle Mode\n",
      "Disney Sorcerer's Arena\n",
      "Just Dance: Disney Party\n"
     ]
    }
   ],
   "source": [
    "# another api exercise on disney\n",
    "import json, requests\n",
    "url = \"https://api.disneyapi.dev/character\"\n",
    "\n",
    "response = requests.get(url)\n",
    "text = response.text\n",
    "data = json.loads(text)\n",
    "\n",
    "for character in data[\"data\"]:\n",
    "    if character[\"name\"] == \"Baloo\":\n",
    "        list = character[\"videoGames\"]\n",
    "\n",
    "print(\"Baloo appears in the following videogames:\\n\")\n",
    "for element in list:\n",
    "    print(element)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Webscraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1378\n"
     ]
    }
   ],
   "source": [
    "import requests, re\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/Elephant\"\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    html = response.text\n",
    "    #print(html)\n",
    "\n",
    "    regex = \"elephant|Elephant\"\n",
    "    matches = re.findall(regex, html)\n",
    "    print(len(matches))\n",
    "else:\n",
    "    print(\"try again\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with beautifulsoup\n",
    "install --> beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\python312\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\python312\\lib\\site-packages (from beautifulsoup4) (2.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>Elephant - Wikipedia</title>\n",
      "Elephant - Wikipedia\n",
      "['Elephant', '-', 'Wikipedia', 'Jump', 'to', 'content', 'Main', 'menu', 'Main', 'menu', 'move', 'to', 'sidebar', 'hide', 'Navigation', 'Main', 'pageContentsCurrent', 'eventsRandom', 'articleAbout', 'WikipediaContact', 'us', 'Contribute', 'HelpLearn', 'to', 'editCommunity', 'portalRecent', 'changesUpload', 'fileSpecial', 'pages', 'Search', 'Search', 'Appearance', 'Donate', 'Create', 'account', 'Log', 'in', 'Personal', 'tools', 'Donate', 'Create', 'account', 'Log', 'in']\n",
      "181\n",
      "343\n",
      "<h3 id=\"Evolution\">Evolution</h3>\n",
      "[<h3 id=\"Evolution\">Evolution</h3>, <h3 id=\"Living_species\">Living species</h3>, <h3 id=\"Ears_and_eyes\">Ears and eyes</h3>, <h3 id=\"Trunk\">Trunk</h3>, <h3 id=\"Teeth\">Teeth</h3>, <h3 id=\"Skin\">Skin</h3>, <h3 id=\"Legs,_locomotion,_and_posture\"><span id=\"Legs.2C_locomotion.2C_and_posture\"></span>Legs, locomotion, and posture</h3>, <h3 id=\"Internal_systems\">Internal systems</h3>, <h3 id=\"Sex_characteristics\">Sex characteristics</h3>, <h3 id=\"Social_organisation\">Social organisation</h3>, <h3 id=\"Sexual_behaviour\">Sexual behaviour</h3>, <h3 id=\"Birth_and_development\">Birth and development</h3>, <h3 id=\"Communication\">Communication</h3>, <h3 id=\"Intelligence_and_cognition\">Intelligence and cognition</h3>, <h3 id=\"Status\">Status</h3>, <h3 id=\"Threats\">Threats</h3>, <h3 id=\"Working_animal\">Working animal</h3>, <h3 id=\"Warfare\">Warfare</h3>, <h3 id=\"Zoos_and_circuses\">Zoos and circuses</h3>, <h3 id=\"Attacks\">Attacks</h3>, <h3 id=\"Cultural_significance\">Cultural significance</h3>]\n",
      "Evolution\n",
      "Living species\n",
      "Ears and eyes\n",
      "Trunk\n",
      "Teeth\n",
      "Skin\n",
      "Legs, locomotion, and posture\n",
      "Internal systems\n",
      "Sex characteristics\n",
      "Social organisation\n",
      "Sexual behaviour\n",
      "Birth and development\n",
      "Communication\n",
      "Intelligence and cognition\n",
      "Status\n",
      "Threats\n",
      "Working animal\n",
      "Warfare\n",
      "Zoos and circuses\n",
      "Attacks\n",
      "Cultural significance\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/Elephant\"\n",
    "response = requests.get(url)\n",
    "html = response.text\n",
    "\n",
    "soup = BeautifulSoup(html)\n",
    "#print(soup)\n",
    "#print(soup.prettify())\n",
    "print(soup.title)\n",
    "print(soup.title.get_text())\n",
    "\n",
    "print(soup.get_text()[0:500].split())\n",
    "print(soup.get_text().count(\"Elephant\"))\n",
    "print(soup.get_text().count(\"elephant\"))\n",
    "\n",
    "h3tags = soup.find(\"h3\")\n",
    "print(h3tags)\n",
    "\n",
    "h3tags = soup.find_all(\"h3\")\n",
    "print(h3tags)\n",
    "\n",
    "for element in h3tags:\n",
    "    print(element.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gajah â€“ Acehnese\n",
      "Olifant â€“ Afrikaans\n",
      "Elefant â€“ Alemannic\n",
      "á‹áˆ†áŠ• â€“ Amharic\n",
      "à¤¹à¤¾à¤¥à¥€ â€“ Angika\n",
      "Elpend â€“ Old English\n",
      "ÙÙŠÙ„ â€“ Arabic\n",
      "Elefant â€“ Aragonese\n",
      "Elefandu â€“ Aromanian\n",
      "Elephantidae â€“ Asturian\n",
      "à¤¹à¤¾à¤¥à¥€ â€“ Awadhi\n",
      "Tapi'itÄ©mbuku â€“ Guarani\n",
      "Fil â€“ Azerbaijani\n",
      "ÙÛŒÙ„ â€“ South Azerbaijani\n",
      "Kunjara â€“ Balinese\n",
      "Sama â€“ Bambara\n",
      "à¦¹à¦¾à¦¤à¦¿ â€“ Bangla\n",
      "Gajah â€“ Banjar\n",
      "ChhiÅ«â¿ â€“ Minnan\n",
      "Ð¤Ð¸Ð» â€“ Bashkir\n",
      "Ð¡Ð»Ð¾Ð½ â€“ Belarusian\n",
      "Ð¡Ð»Ð¾Ð½ â€“ Belarusian (TaraÅ¡kievica orthography)\n",
      "Elepante â€“ Central Bikol\n",
      "Ð¡Ð»Ð¾Ð½ â€“ Bulgarian\n",
      "à½‚à¾³à½„à¼‹à½†à½ºà½“à¼ â€“ Tibetan\n",
      "Slon â€“ Bosnian\n",
      "Olifant â€“ Breton\n",
      "Ð—Ð°Ð°Ð½ â€“ Russia Buriat\n",
      "Elefants â€“ Catalan\n",
      "Slon â€“ Czech\n",
      "Nzou â€“ Shona\n",
      "Elefante â€“ Corsican\n",
      "Eliffant â€“ Welsh\n",
      "WÉ”bigu â€“ Dagbani\n",
      "Elefanter â€“ Danish\n",
      "Elefant â€“ German\n",
      "ChÄ¯ÌÄ¯Ìh yee adilohii â€“ Navajo\n",
      "Elevant â€“ Estonian\n",
      "Î•Î»Î­Ï†Î±Î½Ï„Î±Ï‚ â€“ Greek\n",
      "ÐŸÐ¸Ð» â€“ Erzya\n",
      "Elefante â€“ Spanish\n",
      "Elefanto â€“ Esperanto\n",
      "Elefante â€“ Basque\n",
      "Atiglinyi â€“ Ewe\n",
      "ÙÛŒÙ„ â€“ Persian\n",
      "Haanthi â€“ Fiji Hindi\n",
      "FÃ­lur â€“ Faroese\n",
      "Ã‰lÃ©phant â€“ French\n",
      "Eilifint â€“ Irish\n",
      "Elefant â€“ Manx\n",
      "FillÃ¤r â€“ Gagauz\n",
      "Ailbhean â€“ Scottish Gaelic\n",
      "Elefante â€“ Galician\n",
      "ÐŸÐ¸Ð» â€“ Ingush\n",
      "è±¡ â€“ Gan\n",
      "Njogu â€“ Kikuyu\n",
      "àª¹àª¾àª¥à«€ â€“ Gujarati\n",
      "ðŒ¹ðŒ»ð€ðŒ°ðŒ½ðŒ³ðŒ¿ðƒ â€“ Gothic\n",
      "Siong â€“ Hakka Chinese\n",
      "Ð—Ð°Ð½ â€“ Kalmyk\n",
      "ì½”ë¼ë¦¬ â€“ Korean\n",
      "Giwa â€“ Hausa\n",
      "Õ“Õ²Õ¥Ö€ â€“ Armenian\n",
      "à¤¹à¤¾à¤¥à¥€ â€“ Hindi\n",
      "Slon â€“ Croatian\n",
      "Elefanto â€“ Ido\n",
      "Elepante â€“ Iloko\n",
      "Gajah â€“ Indonesian\n",
      "Indlovu â€“ Zulu\n",
      "FÃ­ll â€“ Icelandic\n",
      "Elefante â€“ Italian\n",
      "×¤×™×œ â€“ Hebrew\n",
      "Gajah â€“ Javanese\n",
      "Nagguaatsoq â€“ Kalaallisut\n",
      "à²†à²¨à³† â€“ Kannada\n",
      "ÛÛ†Ø³ â€“ Kashmiri\n",
      "ÐŸÑ–Ð»Ð´ÐµÑ€ â€“ Kazakh\n",
      "Olifans â€“ Cornish\n",
      "Inzovu â€“ Kinyarwanda\n",
      "Ndovu â€“ Swahili\n",
      "Nzau â€“ Kongo\n",
      "Elefan â€“ Haitian Creole\n",
      "FÃ®l â€“ Kurdish\n",
      "ÐŸÐ¸Ð» â€“ Kyrgyz\n",
      "Elefanc â€“ Ladin\n",
      "ÐŸÐ¸Ð» â€“ Lak\n",
      "àºŠà»‰àº²àº‡ â€“ Lao\n",
      "Elephantus â€“ Latin\n",
      "ZiloÅ†i â€“ Latvian\n",
      "Ð¤Ð¸Ð» â€“ Lezghian\n",
      "Drambliai â€“ Lithuanian\n",
      "Gaza â€“ Nias\n",
      "Elefante â€“ Ligurian\n",
      "Olifante â€“ Limburgish\n",
      "NzÉ”ku â€“ Lingala\n",
      "xanto â€“ Lojban\n",
      "Liofant â€“ Lombard\n",
      "Ð¡Ð»Ð¾Ð½ â€“ Macedonian\n",
      "Elefanta â€“ Malagasy\n",
      "à´†à´¨ â€“ Malayalam\n",
      "Iljunfant â€“ Maltese\n",
      "Arewhana â€“ MÄori\n",
      "à¤¹à¤¤à¥à¤¤à¥€ â€“ Marathi\n",
      "ÙÙŠÙ„ â€“ Egyptian Arabic\n",
      "ÙÛŒÙ„ â€“ Mazanderani\n",
      "Gajah â€“ Malay\n",
      "ê¯ê¯¥ê¯ƒê¯¨ â€“ Manipuri\n",
      "Æ†son â€“ Fanti\n",
      "Gajah â€“ Minangkabau\n",
      "ChiÃ´ng â€“ Mindong\n",
      "Ð—Ð°Ð°Ð½ â€“ Mongolian\n",
      "á€†á€„á€º â€“ Burmese\n",
      "Olifanten â€“ Dutch\n",
      "à¤¹à¤¾à¤¤à¥à¤¤à¥€ â€“ Nepali\n",
      "à¤•à¤¿à¤¸à¤¿ â€“ Newari\n",
      "ã‚¾ã‚¦ â€“ Japanese\n",
      "Elefant â€“ Norwegian Nynorsk\n",
      "ÃŠlÃ©phant â€“ Norman\n",
      "Elefant â€“ Occitan\n",
      "à¬¹à¬¾à¬¤à­€ â€“ Odia\n",
      "Fil â€“ Uzbek\n",
      "à¨¹à¨¾à¨¥à©€ â€“ Punjabi\n",
      "ÛØ§ØªÚ¾ÛŒ â€“ Western Punjabi\n",
      "Olifanti â€“ Papiamento\n",
      "Ù¾ÛŒÙ„ â€“ Pashto\n",
      "áž‚áž‡ážŸáž¶ážš â€“ Khmer\n",
      "Elefant â€“ Low German\n",
      "SÅ‚onie â€“ Polish\n",
      "Elefante â€“ Portuguese\n",
      "Fil â€“ Crimean Tatar\n",
      "Elefant â€“ Romanian\n",
      "Ð¡Ð»Ð¾Ð½ â€“ Rusyn\n",
      "Ð¡Ð»Ð¾Ð½ â€“ Russian\n",
      "Ð¡ÑÐ»Ð¸Ð¸Ð»ÑÑ€ â€“ Yakut\n",
      "zu â€“ Sakizaya\n",
      "Elefane â€“ Samoan\n",
      "à¤—à¤œà¤ƒ â€“ Sanskrit\n",
      "á±¦á±Ÿá±¹á±›á±¤ â€“ Santali\n",
      "ÛØ§ØªÚ¾ÛŒ â€“ Saraiki\n",
      "Elephant â€“ Scots\n",
      "Tlou â€“ Southern Sotho\n",
      "Tlou â€“ Northern Sotho\n",
      "Elefanti â€“ Albanian\n",
      "à¶…à¶½à·’ â€“ Sinhala\n",
      "Elephant â€“ Simple English\n",
      "Ù‡Ø§Ù¿ÙŠ â€“ Sindhi\n",
      "Slon â€“ Slovenian\n",
      "Maroodi â€“ Somali\n",
      "ÙÛŒÙ„ â€“ Central Kurdish\n",
      "Slon â€“ Serbian\n",
      "Gajah â€“ Sundanese\n",
      "Norsu â€“ Finnish\n",
      "Elefant â€“ Swedish\n",
      "Gadya â€“ Tagalog\n",
      "à®¯à®¾à®©à¯ˆ â€“ Tamil\n",
      "Ilu â€“ Kabyle\n",
      "Ð¤Ð¸Ð» â€“ Tatar\n",
      "á¸á¢á€„á€ºá‚‰ â€“ Shan\n",
      "zo â€“ Atayal\n",
      "à°à°¨à±à°—à± â€“ Telugu\n",
      "à¸Šà¹‰à¸²à¸‡ â€“ Thai\n",
      "AkÉ”ÌˆÉ”Ìˆn â€“ Dinka\n",
      "Ð¤Ð¸Ð» â€“ Tajik\n",
      "áŽ§áŽ¹áŽ¹ â€“ Cherokee\n",
      "TsÃªhe'ÃªseesÃ©he â€“ Cheyenne\n",
      "Ná¸“ou â€“ Venda\n",
      "à²†à²¨à³† â€“ Tulu\n",
      "Fil â€“ Turkish\n",
      "Pil â€“ Turkmen\n",
      "Zwuom â€“ Tyap\n",
      "Ð¡Ð»Ð¾Ð½ â€“ Udmurt\n",
      "Ð¡Ð»Ð¾Ð½ â€“ Ukrainian\n",
      "ÛØ§ØªÚ¾ÛŒ â€“ Urdu\n",
      "Ù¾Ù‰Ù„ â€“ Uyghur\n",
      "Duzciengh â€“ Zhuang\n",
      "Elefant â€“ Veps\n",
      "Voi â€“ Vietnamese\n",
      "Leefad â€“ VolapÃ¼k\n",
      "Elevant â€“ VÃµro\n",
      "è±¡ â€“ Literary Chinese\n",
      "Olifantn â€“ West Flemish\n",
      "Elepante â€“ Waray\n",
      "Ã‘ay â€“ Wolof\n",
      "è±¡ â€“ Wu\n",
      "×”×¢×œ×¤×× ×“ â€“ Yiddish\n",
      "Erin â€“ Yoruba\n",
      "è±¡ â€“ Cantonese\n",
      "Fil â€“ Dimli\n",
      "DromblÄ«s â€“ Samogitian\n",
      "è±¡ â€“ Chinese\n",
      "EniinÌ„ â€“ Obolo\n",
      "Gaja â€“ Batak Mandailing\n",
      "AjinakÃº geli â€“ Fon\n",
      "Gajah â€“ Iban\n",
      "KÇmowon â€“ Central Kanuri\n",
      "á¥“á¥£á¥’á¥³ â€“ Tai Nuea\n"
     ]
    }
   ],
   "source": [
    "# getting all of the languages and elephants in those languages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/Elephant\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text)\n",
    "\n",
    "listTags = soup.find_all(\"li\", {'class':\"interlanguage-link\"})\n",
    "for tag in listTags:\n",
    "    print(tag.a[\"title\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More images and regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/wikipedia.png\n",
      "/Soup_powder.jpg\n",
      "/Soup_Course_New.jpg\n",
      "/Seafood_chowder.jpg\n",
      "/Borscht_with_bread.jpg\n",
      "/Vegetable_beef_barley_soup.jpg\n",
      "/Chicken_Noodle_Soup.jpg\n",
      "/Reindeer_cheese_soup.jpg\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests, re\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/Soup\"\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(r.text)\n",
    "\n",
    "imgTags = soup.find_all('img')\n",
    "sources = [img['src'] for img in imgTags]\n",
    "\n",
    "results = re.findall(r'(/\\w+[.](jpg|png|gif))',str(sources))\n",
    "for url in results:\n",
    "    print(url[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#downloading images and storing them somewhere --> from weather website\n",
    "#https://www.meteoblue.com/nl/weer/webcams/kopenhagen_denemarken_2618425\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "url = \"https://www.meteoblue.com/nl/weer/webcams/kopenhagen_denemarken_2618425\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content,\"html.parser\")\n",
    "\n",
    "images = soup.find_all('img')\n",
    "\n",
    "#os.mkdir(f\"{os.getcwd()}/Images\") --> add this only 1 time to immediately create a folder and add all files/images there\n",
    "\n",
    "count = 0\n",
    "for img in images:\n",
    "    url = img[\"src\"]\n",
    "    filename = f\"Images/meteoblue_{str(count)}.jpg\"\n",
    "    r = requests.get(url, allow_redirects=True)\n",
    "    with open(filename, 'wb') as file:\n",
    "        file.write(r.content)\n",
    "    count += 1 \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
